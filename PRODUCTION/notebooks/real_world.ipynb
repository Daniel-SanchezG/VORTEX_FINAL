{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6732cda-6bce-4a35-b056-2651d329b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import pickle  \n",
    "import os\n",
    "from pycaret.classification import load_model, predict_model\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9963a-dd79-48b6-9322-5e30b7e6a3a6",
   "metadata": {},
   "source": [
    "setup_function():\n",
    "- load out-of-sample data\n",
    "- load all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc9535-a008-44ae-9266-03328e0317c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading different datasets\n",
    "#df = pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='quiruelas', engine='openpyxl')\n",
    "#df = pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='v_higueras', engine='openpyxl')\n",
    "#df = pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='Alberite', engine='openpyxl')\n",
    "#df = pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='Paternanbidea', engine='openpyxl')\n",
    "#df = pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='Can_Gambus', engine='openpyxl')\n",
    "#df = pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='CatalonianSites', engine='openpyxl')\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe070084-d417-4ab8-8990-24c9a7e068b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading models\n",
    "full_model = load_model(model_path)\n",
    "destilled_model = load_model(model_path)\n",
    "#specific\n",
    "VdH = load_model(model_path)\n",
    "PQ = load_model(model_path)\n",
    "French = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468168c9-8a45-4d15-b1ab-59473f9df843",
   "metadata": {},
   "source": [
    "### Prediction_function():\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49edbc-2cd4-4d2d-aa1d-035ebfa120ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediction(model_path, excel_path, exclude_columns=None, output_column='predictions'):\n",
    "    \"\"\"\n",
    "    Carga un archivo Excel,\n",
    "    hace predicciones usando un modelo pre-entrenado,\n",
    "    y guarda los resultados en un nuevo archivo Excel o CSV.\n",
    "\n",
    "    :param model_path: Ruta al archivo del modelo \n",
    "    :param excel_path: Ruta al archivo con los datos de entrada\n",
    "    :param exclude_columns: Lista de columnas a excluir como entrada (opcional)\n",
    "    :param output_column: Nombre de la columna para las predicciones (por defecto: 'predictions')\n",
    "    :return: Ruta al archivo de salida con las predicciones\n",
    "    \"\"\"\n",
    "    # Loading  the model usando PyCaret\n",
    "    modelo = load_model(model_path)\n",
    "\n",
    "    # Cargar los datos\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "\n",
    "    # Excluir columnas si se especifican\n",
    "    if exclude_columns:\n",
    "        df = df.drop(columns=[col for col in exclude_columns], errors='ignore')\n",
    "\n",
    "    # Hacer predicciones usando PyCaret\n",
    "    predictions = predict_model(model, data=df,raw_score=True)\n",
    "    \n",
    "    # El resultado de predict_model ya incluye las predicciones, \n",
    "    # generalmente en una columna llamada 'Label' o similar\n",
    "    # Renombrar la columna de predicciones si es necesario\n",
    "    if 'Label' in predicciones.columns:\n",
    "        predicciones = predicciones.rename(columns={'Label': output_column})\n",
    "    elif 'prediction_label' in predicciones.columns:\n",
    "        predicciones = predicciones.rename(columns={'prediction_label': output_column})\n",
    "    else:\n",
    "        # Si la columna de predicciones tiene otro nombre, ajusta esto según sea necesario\n",
    "        pass\n",
    "\n",
    "   \n",
    "    # Create name for the output file\n",
    "    base_name = os.path.splitext(excel_path)[0]\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    output_path = f\"{base_name}_{current_date}_predictions.xlsx\"\n",
    "   \n",
    "\n",
    "    # save results\n",
    "    predictions.to_excel(output_path, index=False)\n",
    "    predictions.to_csv(output_path, index=False)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a773dee-c50b-4f04-863f-35a9424ae9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage:\n",
    "model_path = '20240827_SinCaDestilledVortex2SMOTECalibrated'\n",
    "excel_path = \"./DATA/VARISCITA ROMANA100.xlsx\"\n",
    "exclude_columns = [] \n",
    "\n",
    "try:\n",
    "    output_file = predict_from_excel(model_path, excel_path, exclude_columns)\n",
    "    print(f\"Predictions saved in: {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46397d4-aa6e-481e-93f2-2f656f54d75e",
   "metadata": {},
   "source": [
    "\n",
    "class ProvenanceAndUncertaintyAnalysis:\n",
    "\n",
    "- def predictions_uncertain analysis():\n",
    "  - Confidence treshold >0.7\n",
    "  - Average confidence per site\n",
    "  - Median entropy per site\n",
    "  - Median probabilities per site\n",
    "\n",
    "- def provenance_determination():\n",
    "  - Majority vote sourcing\n",
    "  - Homogeneity\n",
    "  - summary table\n",
    "    - Site\n",
    "    - Samples Analyzed\n",
    "    - Samples sourced to Gavá\n",
    "    - Samples sourced to Aliste\n",
    "    - Samples sourced to Encinasola\n",
    "    - Median entropy per site\n",
    "    - (%) of uncertain samples\n",
    "    - number of samples used for sourcing\n",
    "    - Majority vote sourcing\n",
    "    - Homogenity\n",
    "\n",
    " \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e97a6529-bbb4-425b-bcf7-501014c47f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predictions_uncertainty_analysis(prediction_df, confidence_threshold=0.7):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Performs uncertainty analysis per site\n",
    "\n",
    "    Args:\n",
    "        prediction_df: df with probabilistic predictions\n",
    "        confidence_treshold: threshold to mark the prediction as uncertain\n",
    "     \n",
    "    \"\"\"\n",
    "    # Convert score columns to numbers\n",
    "    score_cols = ['prediction_score_CT', 'prediction_score_PCM', 'prediction_score_PDLC']\n",
    "    for col in score_cols:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    # Obtaining probabilities\n",
    "    probas = df[score_cols].values\n",
    "    \n",
    "    # Obtain prediction labels and confidence\n",
    "    predictions = df['predicciones'].values\n",
    "    confidences = np.max(probas, axis=1)\n",
    "    \n",
    "    # Marking predictions below the threshold as uncertain\n",
    "    uncertain_mask = confidences < confidence_threshold\n",
    "    predictions_with_uncertainty = predictions.copy()\n",
    "    predictions_with_uncertainty[uncertain_mask] = 'uncertain'\n",
    "    \n",
    "    # Calculate entropy \n",
    "    entropies = np.array([entropy(probs, base=2) for probs in probas])\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'id': df['id'],\n",
    "        'Site': df['Site'],\n",
    "        'Original_predictions': predictions,\n",
    "        'prediction_score_CT': df['prediction_score_CT'],\n",
    "        'prediction_score_PCM':df['prediction_score_PCM'],\n",
    "        'prediction_score_PDLC': df['prediction_score_PDLC'],\n",
    "        'Uncertainty_treshold_predictions': predictions_with_uncertainty,\n",
    "        'entropy': entropies\n",
    "    })\n",
    "    \n",
    "    # Print basic metrics\n",
    "    n_uncertain = np.sum(uncertain_mask)\n",
    "    print(f\"Uncertain predictions: {n_uncertain}/{len(df)} ({(n_uncertain/len(df)*100):.1f}%)\")\n",
    "    print(f\"Mean dataset entropy: {entropies.mean():.3f}\")\n",
    "    \n",
    "    \n",
    "    # Calculate and display median entropy per site\n",
    "    print(\"\\nMedian entropy per site:\")\n",
    "    entropy_median_by_site = results_df.groupby('Site')['entropy'].median()\n",
    "    for site, median in entropy_median_by_site.items():\n",
    "        print(f\"{site}: {median:.3f}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e66e2d14-1465-4b8a-ad04-9e3934e27422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertain predictions: 147/576 (25.5%)\n",
      "Mean dataset entropy: 0.794\n",
      "\n",
      "Median entropy per site:\n",
      "Auverné: 0.710\n",
      "Can Gambús I: 0.233\n",
      "Can Sadurni: 1.489\n",
      "Cova Cassimanya: 1.409\n",
      "Dolmen de Alberite: 0.343\n",
      "Josseliére: 0.710\n",
      "Kervilor: 0.710\n",
      "La serreta: 0.882\n",
      "Luffang: 0.721\n",
      "Paternanbidea: 0.555\n",
      "Peñas Quiruelas: 0.757\n",
      "Plichancourt: 0.738\n",
      "Roca de L'ivet: 1.462\n",
      "Tumulus St Michel: 0.710\n",
      "Valle de las Higueras: 0.876\n",
      "\n",
      "Primeras 5 filas de resultados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Site</th>\n",
       "      <th>Original_predictions</th>\n",
       "      <th>prediction_score_CT</th>\n",
       "      <th>prediction_score_PCM</th>\n",
       "      <th>prediction_score_PDLC</th>\n",
       "      <th>Uncertainty_treshold_predictions</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP-865</td>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.134419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP-824</td>\n",
       "      <td>Roca de L'ivet</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.539798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP-795</td>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.491318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP-797</td>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.496356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP-823</td>\n",
       "      <td>Roca de L'ivet</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.530894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            Site Original_predictions  prediction_score_CT  \\\n",
       "0  MP-865     Can Sadurni                   CT                 0.72   \n",
       "1  MP-824  Roca de L'ivet                 PDLC                 0.22   \n",
       "2  MP-795     Can Sadurni                   CT                 0.48   \n",
       "3  MP-797     Can Sadurni                 PDLC                 0.19   \n",
       "4  MP-823  Roca de L'ivet                 PDLC                 0.22   \n",
       "\n",
       "   prediction_score_PCM  prediction_score_PDLC  \\\n",
       "0                  0.13                   0.15   \n",
       "1                  0.38                   0.40   \n",
       "2                  0.33                   0.19   \n",
       "3                  0.34                   0.47   \n",
       "4                  0.34                   0.44   \n",
       "\n",
       "  Uncertainty_treshold_predictions   entropy  \n",
       "0                               CT  1.134419  \n",
       "1                        uncertain  1.539798  \n",
       "2                        uncertain  1.491318  \n",
       "3                        uncertain  1.496356  \n",
       "4                        uncertain  1.530894  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar y procesar datos\n",
    "df = pd.read_csv('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/20241118_PrediccionesVortexTodas.csv',encoding='latin-1')\n",
    "results = predictions_uncertainty_analysis(df, confidence_threshold=0.7)\n",
    "\n",
    "# Mostrar primeras filas de resultados\n",
    "print(\"\\nPrimeras 5 filas de resultados:\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e17b41e8-96e4-4960-b4f1-f32611513d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def provenance_determination(df):\n",
    "\n",
    "     # Convert score columns to numbers\n",
    "    score_columns = ['prediction_score_CT', 'prediction_score_PCM', 'prediction_score_PDLC']\n",
    "    #for col in score_cols:\n",
    "        #df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    df['max_prob'] = df[score_columns].max(axis=1)\n",
    "    \n",
    "    results = []\n",
    "    for site in df['Site'].unique():\n",
    "        site_data = df[df['Site'] == site]\n",
    "        #n_uncertain = sum(site_data['max_prob'] < 0.70)\n",
    "        avg_uncertain = sum(site_data['max_prob'] < 0.70)/ len(site_data)*100\n",
    "        high_conf = site_data[site_data['max_prob'] > 0.70]\n",
    "        median_entropy = site_data.entropy.median()\n",
    "        \n",
    "        if len(high_conf) > 0:\n",
    "            consensus = high_conf['Uncertainty_treshold_predictions'].mode().iloc[0] # majority vote as mode of high confidence samples\n",
    "            consistency = sum(high_conf['Uncertainty_treshold_predictions'] == consensus) / len(high_conf)\n",
    "            n_consensus_pred = len(high_conf)  # Número de predicciones usadas\n",
    "        else:\n",
    "            consensus = 'No consensus'\n",
    "            consistency = 0\n",
    "            n_consensus_pred = 0\n",
    "            \n",
    "        results.append({\n",
    "            'Site': site,\n",
    "            'Samples_analyzed': len(site_data),\n",
    "            'Gavá': len(site_data[site_data['Original_predictions'] == 'CT']) ,\n",
    "            'Encinasola': len(site_data[site_data['Original_predictions'] == 'PCM']),\n",
    "            'Aliste': len(site_data[site_data['Original_predictions'] == 'PDLC']),\n",
    "            'Uncertain(%)': round(avg_uncertain),\n",
    "            'Samples_for_provenance': n_consensus_pred,\n",
    "            'Median_entropy': round(median_entropy,2),\n",
    "            'Consensus': consensus,\n",
    "            'Homogeneity': round(consistency,2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec194946-33ee-40a8-b8a5-2e60ab6824e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Samples_analyzed</th>\n",
       "      <th>Gavá</th>\n",
       "      <th>Encinasola</th>\n",
       "      <th>Aliste</th>\n",
       "      <th>Uncertain(%)</th>\n",
       "      <th>Samples_for_provenance</th>\n",
       "      <th>Median_entropy</th>\n",
       "      <th>Consensus</th>\n",
       "      <th>Homogeneity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1.49</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roca de L'ivet</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.46</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La serreta</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>0.88</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cova Cassimanya</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.41</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Valle de las Higueras</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>241</td>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>0.88</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peñas Quiruelas</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>0.76</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Luffang</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.72</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tumulus St Michel</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Auverné</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Josseliére</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kervilor</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Plichancourt</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dolmen de Alberite</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Paternanbidea</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.56</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Can Gambús I</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>0.23</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Site  Samples_analyzed  Gavá  Encinasola  Aliste  \\\n",
       "0             Can Sadurni                 8     6           0       2   \n",
       "1          Roca de L'ivet                16     1           3      12   \n",
       "2              La serreta                59    58           0       1   \n",
       "3         Cova Cassimanya                12    10           0       2   \n",
       "4   Valle de las Higueras               276    14          21     241   \n",
       "5         Peñas Quiruelas                52     0           5      47   \n",
       "6                 Luffang                 9     0           0       9   \n",
       "7       Tumulus St Michel                 3     0           0       3   \n",
       "8                 Auverné                 3     0           0       3   \n",
       "9              Josseliére                 9     0           0       9   \n",
       "10               Kervilor                35     0           0      35   \n",
       "11           Plichancourt                 2     0           0       2   \n",
       "12     Dolmen de Alberite                10     9           0       1   \n",
       "13          Paternanbidea                 4     1           0       3   \n",
       "14           Can Gambús I                78    74           1       3   \n",
       "\n",
       "    Uncertain(%)  Samples_for_provenance  Median_entropy Consensus  \\\n",
       "0             75                       2            1.49        CT   \n",
       "1             94                       1            1.46      PDLC   \n",
       "2             27                      42            0.88        CT   \n",
       "3             75                       3            1.41        CT   \n",
       "4             31                     191            0.88      PDLC   \n",
       "5             19                      42            0.76      PDLC   \n",
       "6              0                       9            0.72      PDLC   \n",
       "7              0                       3            0.71      PDLC   \n",
       "8              0                       3            0.71      PDLC   \n",
       "9              0                       9            0.71      PDLC   \n",
       "10             0                      35            0.71      PDLC   \n",
       "11             0                       2            0.74      PDLC   \n",
       "12            10                       9            0.34        CT   \n",
       "13            25                       3            0.56      PDLC   \n",
       "14             5                      74            0.23        CT   \n",
       "\n",
       "    Homogeneity  \n",
       "0          1.00  \n",
       "1          1.00  \n",
       "2          1.00  \n",
       "3          1.00  \n",
       "4          0.97  \n",
       "5          0.98  \n",
       "6          1.00  \n",
       "7          1.00  \n",
       "8          1.00  \n",
       "9          1.00  \n",
       "10         1.00  \n",
       "11         1.00  \n",
       "12         1.00  \n",
       "13         1.00  \n",
       "14         0.99  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = provenance_determination(results)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f76c2-f826-4fdf-8f33-0df876314563",
   "metadata": {},
   "source": [
    "Plotting function:\n",
    "- Create uncertain plot\n",
    "- Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457b1de-0434-4eee-bb69-65c9b9aaaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
