#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Script para ejecutar el pipeline completo de an√°lisis arqueol√≥gico
-----------------------------------------------------------------
Integra predicci√≥n, an√°lisis de incertidumbre, determinaci√≥n de procedencia
y visualizaci√≥n de resultados.

Ejemplo de uso:
    python run_predictions_with_uncertainty_and_provenance.py
"""

import os
import sys
import datetime
import logging

# Asegurarse de que el directorio actual est√© en el path de Python
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Importar los m√≥dulos necesarios
from archaeological_predictor import ArchaeologicalPredictor
from uncertainty_analysis import process_predictions_with_uncertainty
from provenance_determination import process_provenance_determination
from visualization import generate_visualization

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f"archaeological_pipeline_{datetime.datetime.now().strftime('%Y%m%d')}.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("ArchaeologicalPipeline")

# Configuraci√≥n de rutas - ajustar seg√∫n la estructura en producci√≥n
BASE_DIR = '/home/dsg/VORTEX_FINAL/PRODUCTION'
DATA_PATH = os.path.join(BASE_DIR, 'DATA/real_world/real_world_data.xlsx')
MODELS_DIR = os.path.join(BASE_DIR, 'models')
OUTPUT_DIR = os.path.join(BASE_DIR, 'real_world_results')

# Crear directorio de resultados si no existe
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Generar nombres de archivos de salida
current_date = datetime.datetime.now().strftime("%Y%m%d")
prediction_file = os.path.join(OUTPUT_DIR, f"archaeological_predictions_{current_date}.xlsx")
uncertainty_file = os.path.join(OUTPUT_DIR, f"uncertainty_analysis_{current_date}.xlsx")
provenance_file = os.path.join(OUTPUT_DIR, f"provenance_analysis_{current_date}.xlsx")
visualization_file = os.path.join(OUTPUT_DIR, f"site_entropy_distribution_{current_date}.png")
statistics_file = os.path.join(OUTPUT_DIR, f"site_statistics_{current_date}")

def run_complete_pipeline(skip_uncertainty=False, skip_provenance=False, 
                         skip_visualization=False, confidence_threshold=0.7):
    """
    Ejecuta el pipeline completo: predicciones, incertidumbre, procedencia y visualizaci√≥n.
    
    Args:
        skip_uncertainty (bool): Si True, omite el an√°lisis de incertidumbre.
        skip_provenance (bool): Si True, omite la determinaci√≥n de procedencia.
        skip_visualization (bool): Si True, omite la generaci√≥n de visualizaciones.
        confidence_threshold (float): Umbral de confianza para an√°lisis.
    
    Returns:
        bool: True si el proceso complet√≥ con √©xito, False en caso contrario.
    """
    print(f"Iniciando pipeline completo de an√°lisis arqueol√≥gico...")
    print(f"Datos: {DATA_PATH}")
    print(f"Modelos: {MODELS_DIR}")
    print(f"Salida: {OUTPUT_DIR}")
    
    # Variables para almacenar DataFrames intermedios
    prediction_df = None
    uncertainty_df = None
    
    try:
        #-----------------------------------------------------------------
        # PASO 1: Generar predicciones
        #-----------------------------------------------------------------
        logger.info("=== INICIANDO SISTEMA DE PREDICCI√ìN ARQUEOL√ìGICA ===")
        print(f"\nüìä PASO 1: Generando predicciones arqueol√≥gicas...")
        
        predictor = ArchaeologicalPredictor(DATA_PATH, MODELS_DIR)
        prediction_path = predictor.run_prediction_pipeline(prediction_file)
        
        if not prediction_path:
            logger.error("Fall√≥ el proceso de predicci√≥n arqueol√≥gica. Abortando pipeline.")
            print("\n‚ùå El proceso de predicci√≥n fall√≥. Abortando pipeline.")
            return False
        
        logger.info(f"Predicciones guardadas en: {prediction_path}")
        print(f"‚úÖ Predicciones generadas correctamente.")
        print(f"   Archivo: {prediction_path}")
        
        #-----------------------------------------------------------------
        # PASO 2: An√°lisis de incertidumbre (opcional)
        #-----------------------------------------------------------------
        if skip_uncertainty:
            logger.info("An√°lisis de incertidumbre omitido por configuraci√≥n.")
            print("\nüîç PASO 2: An√°lisis de incertidumbre omitido seg√∫n configuraci√≥n.")
            
            if not skip_provenance or not skip_visualization:
                logger.error("No se pueden realizar an√°lisis posteriores sin an√°lisis de incertidumbre.")
                print("\n‚ùå No se pueden realizar an√°lisis posteriores sin an√°lisis de incertidumbre.")
                return True  # Retornamos True porque al menos las predicciones se generaron
            
            return True
        
        logger.info("=== INICIANDO AN√ÅLISIS DE INCERTIDUMBRE ===")
        print(f"\nüîç PASO 2: Realizando an√°lisis de incertidumbre...")
        
        # Ejecutar an√°lisis de incertidumbre
        uncertainty_df = process_predictions_with_uncertainty(
            prediction_path=prediction_path,
            output_path=uncertainty_file,
            confidence_threshold=confidence_threshold
        )
        
        if uncertainty_df is None:
            logger.error("Fall√≥ el an√°lisis de incertidumbre. Abortando an√°lisis posteriores.")
            print("\n‚ö†Ô∏è El an√°lisis de incertidumbre fall√≥. No se puede continuar.")
            return True  # Retornar True porque al menos las predicciones se generaron
        
        logger.info(f"An√°lisis de incertidumbre completado y guardado en: {uncertainty_file}")
        print(f"‚úÖ An√°lisis de incertidumbre completado.")
        print(f"   Archivo: {uncertainty_file}")
        
        #-----------------------------------------------------------------
        # PASO 3: Determinaci√≥n de procedencia (opcional)
        #-----------------------------------------------------------------
        if skip_provenance:
            logger.info("Determinaci√≥n de procedencia omitida por configuraci√≥n.")
            print("\nüîé PASO 3: Determinaci√≥n de procedencia omitida seg√∫n configuraci√≥n.")
        else:
            logger.info("=== INICIANDO DETERMINACI√ìN DE PROCEDENCIA ===")
            print(f"\nüîé PASO 3: Realizando determinaci√≥n de procedencia...")
            
            # Ejecutar determinaci√≥n de procedencia
            provenance_df = process_provenance_determination(
                uncertainty_df=uncertainty_df,
                output_path=provenance_file,
                confidence_threshold=confidence_threshold
            )
            
            if provenance_df is None:
                logger.error("Fall√≥ la determinaci√≥n de procedencia.")
                print("\n‚ö†Ô∏è La determinaci√≥n de procedencia fall√≥.")
            else:
                logger.info(f"Determinaci√≥n de procedencia completada y guardada en: {provenance_file}")
                print(f"‚úÖ Determinaci√≥n de procedencia completada.")
                print(f"   Archivo: {provenance_file}")
        
        #-----------------------------------------------------------------
        # PASO 4: Visualizaci√≥n (opcional)
        #-----------------------------------------------------------------
        if skip_visualization:
            logger.info("Generaci√≥n de visualizaciones omitida por configuraci√≥n.")
            print("\nüìà PASO 4: Generaci√≥n de visualizaciones omitida seg√∫n configuraci√≥n.")
        else:
            logger.info("=== INICIANDO GENERACI√ìN DE VISUALIZACIONES ===")
            print(f"\nüìà PASO 4: Generando visualizaciones de entrop√≠a...")
            
            # Generar visualizaciones
            vis_results = generate_visualization(
                uncertainty_df=uncertainty_df,
                output_dir=OUTPUT_DIR,
                entropy_col='Entropy'  # Usar el nombre exacto de la columna
            )
            
            if not vis_results:
                logger.error("Fall√≥ la generaci√≥n de visualizaciones.")
                print("\n‚ö†Ô∏è La generaci√≥n de visualizaciones fall√≥.")
            else:
                logger.info("Visualizaciones generadas correctamente.")
                print(f"‚úÖ Visualizaciones generadas correctamente.")
                
                if 'visualization' in vis_results:
                    print(f"   Gr√°fico: {vis_results['visualization']}")
                
                if 'statistics' in vis_results and 'excel' in vis_results['statistics']:
                    print(f"   Estad√≠sticas: {vis_results['statistics']['excel']}")
        
        print("\nüèÜ PIPELINE COMPLETO EJECUTADO CON √âXITO!")
        return True
        
    except Exception as e:
        logger.error(f"Error en el pipeline: {str(e)}")
        print(f"\n‚ùå Error ejecutando el pipeline: {str(e)}")
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Pipeline completo de an√°lisis arqueol√≥gico')
    parser.add_argument('--data', help='Ruta al archivo Excel con datos arqueol√≥gicos')
    parser.add_argument('--models', help='Directorio que contiene los modelos entrenados')
    parser.add_argument('--output', help='Directorio para guardar resultados')
    parser.add_argument('--threshold', type=float, default=0.7, help='Umbral de confianza (por defecto: 0.7)')
    parser.add_argument('--no-uncertainty', action='store_true', help='Omitir an√°lisis de incertidumbre')
    parser.add_argument('--no-provenance', action='store_true', help='Omitir determinaci√≥n de procedencia')
    parser.add_argument('--no-visualization', action='store_true', help='Omitir generaci√≥n de visualizaciones')
    
    args = parser.parse_args()
    
    # Actualizar configuraci√≥n si se proporcionan argumentos
    if args.data:
        DATA_PATH = args.data
    if args.models:
        MODELS_DIR = args.models
    if args.output:
        OUTPUT_DIR = args.output
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # Actualizar rutas de salida
        prediction_file = os.path.join(OUTPUT_DIR, f"archaeological_predictions_{current_date}.xlsx")
        uncertainty_file = os.path.join(OUTPUT_DIR, f"uncertainty_analysis_{current_date}.xlsx")
        provenance_file = os.path.join(OUTPUT_DIR, f"provenance_analysis_{current_date}.xlsx")
        visualization_file = os.path.join(OUTPUT_DIR, f"site_entropy_distribution_{current_date}.png")
        statistics_file = os.path.join(OUTPUT_DIR, f"site_statistics_{current_date}")
    
    # Ejecutar pipeline
    success = run_complete_pipeline(
        skip_uncertainty=args.no_uncertainty,
        skip_provenance=args.no_provenance,
        skip_visualization=args.no_visualization,
        confidence_threshold=args.threshold
    )
    
    # Salir con c√≥digo apropiado
    exit(0 if success else 1)
