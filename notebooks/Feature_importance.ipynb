{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f23791-0728-4367-856e-a1f380424122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import * # Machine learning tools\n",
    "from sklearn.metrics import ConfusionMatrixDisplay # Model evaluation\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report # Model evaluation report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import shap\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9782d4f-bf8d-46cb-99fe-3d85bd25146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_excel('/home/dsg/vortex/PRODUCTION/DATA/processed/training_data.xlsx', engine='openpyxl')\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbb391-01ee-4f85-a017-4df0b5977dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setup \n",
    "\n",
    "experiment = setup(data=training_data, target= 'Site',train_size=0.8, session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24418e-3ba6-4136-9fbf-1584aca0db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_metric('MCC')\n",
    "remove_metric('Kappa')\n",
    "remove_metric('AUC')\n",
    "#'AUC', , 'MCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781b554-ab29-4dde-84a7-1300180b9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = create_model('rf', class_weight=\"balanced\", criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe3c1e-0d5f-4213-9175-705c4ac43165",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = tune_model(rf, n_iter=10, tuner_verbose=True, optimize='F1', custom_grid = {'criterion': ['entropy']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b4f44-33bb-477d-9ce9-e6a481e365f9",
   "metadata": {},
   "source": [
    "### Calculating feature importance using RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7686a0-faec-482f-bc3b-a5ce9c1a37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = get_config('X_train')\n",
    "y_training= get_config('y_train')\n",
    "training_data['Site'] = y_training\n",
    "y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d328145-baa8-4d2a-8cc8-aaeb894e3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_config('X_train')\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952ab1d-2856-4c80-981e-c57429e7e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvcdf = training_data  \n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = rvcdf.drop(['Site', 'rand'], axis=1)\n",
    "y = rvcdf['Site']\n",
    "rvcdf['Site'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9653d-c6a0-4c6a-bbf8-694375ee03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c50b4d-a0be-4c3e-8de6-e1a9c112f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV loop\n",
    "def run_rfecv(X, y, tuned_model, random_state):\n",
    "    np.random.seed(random_state)  # Set seed for any numpy operations\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
    "    rfecv = RFECV(estimator=clone(tuned_model), step=2, cv=cv, scoring='accuracy')\n",
    "    rfecv.fit(X, y)\n",
    "    \n",
    "    # Handle different scikit-learn versions\n",
    "    if hasattr(rfecv, 'cv_results_'):\n",
    "        # For newer scikit-learn versions\n",
    "        grid_scores = rfecv.cv_results_['mean_test_score']\n",
    "    elif hasattr(rfecv, 'grid_scores_'):\n",
    "        # For older scikit-learn versions\n",
    "        grid_scores = rfecv.grid_scores_\n",
    "    else:\n",
    "        raise AttributeError(\"RFECV object has neither 'cv_results_' nor 'grid_scores_' attribute\")\n",
    "    \n",
    "    # Get the mask of selected features\n",
    "    feature_mask = rfecv.support_\n",
    "    \n",
    "    return rfecv.n_features_, grid_scores, feature_mask\n",
    "\n",
    "# Number of times to run the process\n",
    "n_runs = 10\n",
    "\n",
    "# Lists to store results\n",
    "n_features_list = []\n",
    "grid_scores_list = []\n",
    "feature_masks = []\n",
    "\n",
    "# Run the process multiple times\n",
    "for i in range(n_runs):\n",
    "    n_features, grid_scores, feature_mask = run_rfecv(X, y, tuned_model, random_state=i)\n",
    "    n_features_list.append(n_features)\n",
    "    grid_scores_list.append(grid_scores)\n",
    "    feature_masks.append(feature_mask)\n",
    "\n",
    "# Calculate average and variance of optimal number of features\n",
    "avg_n_features = np.mean(n_features_list)\n",
    "var_n_features = np.var(n_features_list)\n",
    "\n",
    "print(f\"Average optimal number of features: {avg_n_features:.2f}\")\n",
    "print(f\"Variance in optimal number of features: {var_n_features:.2f}\")\n",
    "\n",
    "# Calculate average and variance of grid scores\n",
    "avg_grid_scores = np.mean(grid_scores_list, axis=0)\n",
    "var_grid_scores = np.var(grid_scores_list, axis=0)\n",
    "\n",
    "\n",
    "# Print the range of optimal features\n",
    "min_features = min(n_features_list)\n",
    "max_features = max(n_features_list)\n",
    "print(f\"Range of optimal number of features: {min_features} to {max_features}\")\n",
    "feature_selection_counts = Counter()\n",
    "for mask in feature_masks:\n",
    "    feature_selection_counts.update(np.where(mask)[0])\n",
    "\n",
    "total_runs = len(feature_masks)\n",
    "consistent_features = [feature for feature, count in feature_selection_counts.items() \n",
    "                       if count == total_runs]\n",
    "mostly_consistent_features = [feature for feature, count in feature_selection_counts.items() \n",
    "                              if count >= total_runs * 0.8]\n",
    "\n",
    "# Map indices to feature names\n",
    "consistent_feature_names = [feature_names[i] for i in consistent_features]\n",
    "mostly_consistent_feature_names = [feature_names[i] for i in mostly_consistent_features]\n",
    "\n",
    "print(\"\\nFeatures selected in all runs:\")\n",
    "for idx, name in zip(consistent_features, consistent_feature_names):\n",
    "    print(f\"Index {idx}: {name}\")\n",
    "\n",
    "print(\"\\nFeatures selected in at least 80% of runs:\")\n",
    "for idx, name in zip(mostly_consistent_features, mostly_consistent_feature_names):\n",
    "    print(f\"Index {idx}: {name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2dbc9d-941c-4a4b-9f55-47e44e2571d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el backend de Matplotlib\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# Modificación en la parte de visualización\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Transponer grid_scores_list para que cada columna represente un número de características\n",
    "grid_scores_transposed = list(map(list, zip(*grid_scores_list)))\n",
    "\n",
    "# Crear el boxplot\n",
    "#bp = ax.boxplot(grid_scores_transposed, positions=range(1, len(avg_grid_scores) + 1), \n",
    "#                widths=0.6, patch_artist=True)\n",
    "\n",
    "# Personalizar el color de los boxplots\n",
    "#for box in bp['boxes']:\n",
    "#    box.set(facecolor='lightblue', edgecolor='blue', alpha=0.7)\n",
    "\n",
    "# Calcular los límites superior e inferior para la región sombreada\n",
    "x = range(1, len(avg_grid_scores) + 1)\n",
    "lower_bound = avg_grid_scores - np.sqrt(var_grid_scores)\n",
    "upper_bound = avg_grid_scores + np.sqrt(var_grid_scores)\n",
    "\n",
    "# Dibujar la región sombreada\n",
    "ax.fill_between(x, lower_bound, upper_bound, color='gray', alpha=0.3)\n",
    "\n",
    "# Dibujar la línea de promedios\n",
    "ax.plot(x, avg_grid_scores, 'o-', color='gray', linewidth=1, markersize=4)\n",
    "\n",
    "# Configurar el gráfico\n",
    "ax.set_xlabel('Number of Features',fontweight='bold', fontsize=14)\n",
    "ax.set_ylabel('Cross-validation Accuracy',fontweight='bold', fontsize=14)\n",
    "#ax.set_title('RFECV Results: Distribution and Average Across Runs', fontsize=16)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.set_xticks(range(1, len(avg_grid_scores) + 1))\n",
    "ax.set_xticklabels(range(1, len(avg_grid_scores) + 1))\n",
    "\n",
    "# Añadir una leyenda\n",
    "ax.plot([], [], 'o-', color='gray', linewidth=1, markersize=4, label='Average Score')\n",
    "ax.fill([], [], color='gray', alpha=0.3, label='Standard Deviation')\n",
    "#ax.plot([], [], 'b-', label='Median Score')\n",
    "#ax.fill([], [], color='lightblue', alpha=0.7, label='Score Distribution')\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Guardar la figura\n",
    "plt.savefig(\"/home/dsg/vortex/PRODUCTION/outputs/plots/RFECV_shaded_.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Cerrar la figura para liberar memoria\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59cb08-14d9-4bab-8560-83dab86013aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_names = X.columns\n",
    "def plot_feature_importance_dotplot(model, feature_names=None, n_features=10):\n",
    "    # Obtener la importancia de las características\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Si no se proporcionan nombres de características, usar índices\n",
    "    if feature_names is None:\n",
    "        feature_names = [f'Feature {i}' for i in range(len(importances))]\n",
    "    \n",
    "    # Crear un DataFrame con las características y sus importancias\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    })\n",
    "    \n",
    "    # Ordenar el DataFrame por importancia descendente\n",
    "    feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Limitar el número de características a visualizar\n",
    "    feature_importance_df = feature_importance_df.head(n_features)\n",
    "    \n",
    "    # Crear el gráfico de puntos\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, n_features * 0.3)))\n",
    "    \n",
    "    # Dibujar líneas horizontales\n",
    "    ax.hlines(y=range(n_features), xmin=0, xmax=feature_importance_df['importance'], color='skyblue')\n",
    "    \n",
    "    # Dibujar puntos\n",
    "    ax.plot(feature_importance_df['importance'], range(n_features), \"o\")\n",
    "    \n",
    "    # Configurar el eje y\n",
    "    ax.set_yticks(range(n_features),)\n",
    "    ax.set_yticklabels(feature_importance_df['feature'])\n",
    "    ax.invert_yaxis()  # Las características más importantes arriba\n",
    "    \n",
    "   \n",
    "    ax.set_xlabel('Feature Importance')\n",
    "    ax.set_ylabel('Features')\n",
    "    # Añadir título y ajustar diseño\n",
    "    #ax.set_title('Feature Importance Plot')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Feature Importance', fontsize=14)\n",
    "    plt.ylabel('Features', fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.savefig('/home/dsg/vortex/PRODUCTION/outputs/plots/14importantFeatures.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Asumiendo que ya tiene su modelo entrenado llamado 'rf_model' y una lista de nombres de características 'feature_names'\n",
    "plot_feature_importance_dotplot(tuned_model, feature_names, n_features=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf44126-bbc1-45f8-9be4-1538a4c81803",
   "metadata": {},
   "source": [
    "### Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd21d1-81c2-45ed-8845-da8a52397ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def custom_interpret_model(model, X_train, plot='summary', feature_name=None, observation=None, \n",
    "                           use_train_data=True, X_new_sample=None, class_names=None, max_display=None,\n",
    "                           save_path=None):\n",
    "    \n",
    "    # Obtener el objeto de explicación SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    # Usar X_train si use_train_data es True, de lo contrario usar X_new_sample si se proporciona\n",
    "    if use_train_data:\n",
    "        data_for_shap = X_train\n",
    "    elif X_new_sample is not None:\n",
    "        data_for_shap = X_new_sample\n",
    "    else:\n",
    "        raise ValueError(\"Debe proporcionar X_new_sample si use_train_data es False\")\n",
    "\n",
    "    shap_values = explainer.shap_values(data_for_shap)\n",
    "\n",
    "    # Crear una nueva figura\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Crear una paleta secuencial de grises personalizada\n",
    "    colors = [(0.6, 0.6, 0.6), (0.1, 0.1, 0.1)]  # Del gris claro al gris oscuro\n",
    "    n_bins = 3  # Número de tonos de gris\n",
    "    gray_cmap = LinearSegmentedColormap.from_list(\"custom_grays\", colors, N=n_bins)\n",
    "\n",
    "    # Generar el summary plot con la paleta de grises personalizada\n",
    "    shap.summary_plot(shap_values, \n",
    "                      data_for_shap,\n",
    "                      plot_type=\"bar\",\n",
    "                      class_names=class_names,\n",
    "                      color=gray_cmap,\n",
    "                      max_display=max_display,\n",
    "                      show=False)  # No mostrar el gráfico inmediatamente\n",
    "\n",
    "    # Ajustar el diseño\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar o mostrar el gráfico\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()  # Cerrar la figura para liberar memoria\n",
    "        print(f\"Gráfico guardado en: {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Ejemplo de uso de la función\n",
    "custom_interpret_model(tuned_model, \n",
    "                        X_train,  # Sus datos de entrenamiento\n",
    "                        class_names=['Gavá', 'Terena', 'Aliste'], \n",
    "                        max_display=14,\n",
    "                        save_path='/home/dsg/vortex/PRODUCTION/outputs/plots/SHAPSummary.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
