{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6732cda-6bce-4a35-b056-2651d329b28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreloadfrom pycaret.classification import load_model, predict_model\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import pickle  \n",
    "import os\n",
    "from pycaret.classification import load_model, predict_model\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59fc9535-a008-44ae-9266-03328e0317c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading different datasets\n",
    "\n",
    "data_pool = {\n",
    "        'pq': pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='quiruelas', engine='openpyxl'),\n",
    "        'vdh': pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='v_higueras', engine='openpyxl'),\n",
    "        'da': pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='Alberite', engine='openpyxl'),\n",
    "        'pa':pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='Paternanbidea', engine='openpyxl'),\n",
    "        'cg':pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='Can_Gambus', engine='openpyxl'),\n",
    "        'cs':pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='CatalonianSites', engine='openpyxl'),\n",
    "        'fs': pd.read_excel('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx',sheet_name='FrenchSites', engine='openpyxl')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe070084-d417-4ab8-8990-24c9a7e068b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " model_pool = {\n",
    "        'destilled_model': '/home/dsg/VORTEX_FINAL/PRODUCTION/notebooks/models/rf_Destilled_calibrated',\n",
    "        'VdHModel':'/home/dsg/VORTEX_FINAL/PRODUCTION/notebooks/models/rf_VdH_calibrated',\n",
    "        'PQModel':'/home/dsg/VORTEX_FINAL/PRODUCTION/notebooks/models/rf_Quiruelas_calibrated',\n",
    "        'FrenchModel':'/home/dsg/VORTEX_FINAL/PRODUCTION/notebooks/models/rf_french_calibrated'\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e706e-6fc4-43ec-92df-dbbb3d6cad8c",
   "metadata": {},
   "source": [
    "The following is a functional example of the prediction function developed. Note that it is not optimised and works for each specific model and dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f49edbc-2cd4-4d2d-aa1d-035ebfa120ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_from_excel(model_path, excel_path, exclude_columns=None, output_column='predicciones'):\n",
    "    \"\"\"\n",
    "    Carga un archivo Excel, añade una columna 'rand' con valores 0,\n",
    "    hace predicciones usando un modelo pre-entrenado de PyCaret,\n",
    "    y guarda los resultados en un nuevo archivo Excel.\n",
    "\n",
    "    :param model_path: Ruta al archivo del modelo guardado con PyCaret\n",
    "    :param excel_path: Ruta al archivo Excel con los datos de entrada\n",
    "    :param exclude_columns: Lista de columnas a excluir como entrada (opcional)\n",
    "    :param output_column: Nombre de la columna para las predicciones (por defecto: 'predicciones')\n",
    "    :return: Ruta al archivo Excel de salida con las predicciones\n",
    "    \"\"\"\n",
    "    # Cargar el modelo usando PyCaret\n",
    "    modelo = load_model(model_path)\n",
    "\n",
    "    # Cargar los datos\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    # Añadir la columna 'rand' con valores 0\n",
    "    df['rand'] = 0\n",
    "\n",
    "    # Excluir columnas si se especifican\n",
    "    if exclude_columns:\n",
    "        df = df.drop(columns=[col for col in exclude_columns if col != 'rand'], errors='ignore')\n",
    "\n",
    "    # Hacer predicciones usando PyCaret\n",
    "    predicciones = predict_model(modelo, data=df,raw_score=True)\n",
    "    #predicciones = predict_model(estimator=modelo, data=df, raw_score=True)\n",
    "\n",
    "    # El resultado de predict_model ya incluye las predicciones, \n",
    "    # generalmente en una columna llamada 'Label' o similar\n",
    "    # Renombrar la columna de predicciones si es necesario\n",
    "    if 'Label' in predicciones.columns:\n",
    "        predicciones = predicciones.rename(columns={'Label': output_column})\n",
    "    elif 'prediction_label' in predicciones.columns:\n",
    "        predicciones = predicciones.rename(columns={'prediction_label': output_column})\n",
    "    else:\n",
    "        # Si la columna de predicciones tiene otro nombre, ajusta esto según sea necesario\n",
    "        pass\n",
    "\n",
    "    # Eliminar la columna 'rand' del resultado final si no se necesita\n",
    "    if 'rand' in predicciones.columns:\n",
    "        predicciones = predicciones.drop(columns=['rand'])\n",
    "\n",
    "    # Crear nombre para el archivo de salida\n",
    "    base_name = os.path.splitext(excel_path)[0]\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "    output_path = f\"{base_name}_{current_date}_predicciones.xlsx\"\n",
    "   #output_path = f\"{base_name}_con_predicciones.xlsx\"\n",
    "\n",
    "    # Guardar resultados\n",
    "    predicciones.to_excel(output_path, index=False)\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a773dee-c50b-4f04-863f-35a9424ae9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Error processing the file: 'dict' object has no attribute 'columns'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage:\n",
    "model_path = './models/rf_VdH_calibrated'\n",
    "excel_path = '/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/real_world/real_world_data.xlsx'\n",
    "exclude_columns = [] \n",
    "\n",
    "try:\n",
    "    output_file = prediction_function(model_path, excel_path, exclude_columns)\n",
    "    print(f\"Predictions saved in: {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a3d3b-d592-4fcc-9275-ddaf50a9917e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e97a6529-bbb4-425b-bcf7-501014c47f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def uncertainty_analysis(prediction_df, confidence_threshold=0.7):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Performs uncertainty analysis per site\n",
    "\n",
    "    Args:\n",
    "        prediction_df: df with probabilistic predictions\n",
    "        confidence_treshold: threshold to mark the prediction as uncertain\n",
    "     \n",
    "    \"\"\"\n",
    "    # Convert score columns to numbers\n",
    "    score_cols = ['prediction_score_CT', 'prediction_score_PCM', 'prediction_score_PDLC']\n",
    "    for col in score_cols:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    # Obtaining probabilities\n",
    "    probas = df[score_cols].values\n",
    "    \n",
    "    # Obtain prediction labels and confidence\n",
    "    predictions = df['predicciones'].values\n",
    "    confidences = np.max(probas, axis=1)\n",
    "    \n",
    "    # Marking predictions below the threshold as uncertain\n",
    "    uncertain_mask = confidences < confidence_threshold\n",
    "    predictions_with_uncertainty = predictions.copy()\n",
    "    predictions_with_uncertainty[uncertain_mask] = 'uncertain'\n",
    "    \n",
    "    # Calculate entropy \n",
    "    entropies = np.array([entropy(probs, base=2) for probs in probas])\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'id': df['id'],\n",
    "        'Site': df['Site'],\n",
    "        'Original_predictions': predictions,\n",
    "        'prediction_score_CT': df['prediction_score_CT'],\n",
    "        'prediction_score_PCM':df['prediction_score_PCM'],\n",
    "        'prediction_score_PDLC': df['prediction_score_PDLC'],\n",
    "        'Uncertainty_treshold_predictions': predictions_with_uncertainty,\n",
    "        'entropy': entropies\n",
    "    })\n",
    "    \n",
    "    # Print basic metrics\n",
    "    n_uncertain = np.sum(uncertain_mask)\n",
    "    print(f\"Uncertain predictions: {n_uncertain}/{len(df)} ({(n_uncertain/len(df)*100):.1f}%)\")\n",
    "    print(f\"Mean dataset entropy: {entropies.mean():.3f}\")\n",
    "    \n",
    "    \n",
    "    # Calculate and display median entropy per site\n",
    "    print(\"\\nMedian entropy per site:\")\n",
    "    entropy_median_by_site = results_df.groupby('Site')['entropy'].median()\n",
    "    for site, median in entropy_median_by_site.items():\n",
    "        print(f\"{site}: {median:.3f}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e66e2d14-1465-4b8a-ad04-9e3934e27422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertain predictions: 147/576 (25.5%)\n",
      "Mean dataset entropy: 0.794\n",
      "\n",
      "Median entropy per site:\n",
      "Auverné: 0.710\n",
      "Can Gambús I: 0.233\n",
      "Can Sadurni: 1.489\n",
      "Cova Cassimanya: 1.409\n",
      "Dolmen de Alberite: 0.343\n",
      "Josseliére: 0.710\n",
      "Kervilor: 0.710\n",
      "La serreta: 0.882\n",
      "Luffang: 0.721\n",
      "Paternanbidea: 0.555\n",
      "Peñas Quiruelas: 0.757\n",
      "Plichancourt: 0.738\n",
      "Roca de L'ivet: 1.462\n",
      "Tumulus St Michel: 0.710\n",
      "Valle de las Higueras: 0.876\n",
      "\n",
      "Primeras 5 filas de resultados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Site</th>\n",
       "      <th>Original_predictions</th>\n",
       "      <th>prediction_score_CT</th>\n",
       "      <th>prediction_score_PCM</th>\n",
       "      <th>prediction_score_PDLC</th>\n",
       "      <th>Uncertainty_treshold_predictions</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MP-865</td>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.134419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP-824</td>\n",
       "      <td>Roca de L'ivet</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.539798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP-795</td>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.491318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP-797</td>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.496356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MP-823</td>\n",
       "      <td>Roca de L'ivet</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1.530894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            Site Original_predictions  prediction_score_CT  \\\n",
       "0  MP-865     Can Sadurni                   CT                 0.72   \n",
       "1  MP-824  Roca de L'ivet                 PDLC                 0.22   \n",
       "2  MP-795     Can Sadurni                   CT                 0.48   \n",
       "3  MP-797     Can Sadurni                 PDLC                 0.19   \n",
       "4  MP-823  Roca de L'ivet                 PDLC                 0.22   \n",
       "\n",
       "   prediction_score_PCM  prediction_score_PDLC  \\\n",
       "0                  0.13                   0.15   \n",
       "1                  0.38                   0.40   \n",
       "2                  0.33                   0.19   \n",
       "3                  0.34                   0.47   \n",
       "4                  0.34                   0.44   \n",
       "\n",
       "  Uncertainty_treshold_predictions   entropy  \n",
       "0                               CT  1.134419  \n",
       "1                        uncertain  1.539798  \n",
       "2                        uncertain  1.491318  \n",
       "3                        uncertain  1.496356  \n",
       "4                        uncertain  1.530894  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all predicitons\n",
    "df = pd.read_csv('./data/All_predictions.csv',encoding='latin-1')\n",
    "results = predictions_uncertainty_analysis(df, confidence_threshold=0.7)\n",
    "\n",
    "# Mostrar primeras filas de resultados\n",
    "print(\"\\nfirst 5 rows of results:\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e17b41e8-96e4-4960-b4f1-f32611513d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def provenance_determination(self, df):\n",
    "\n",
    "    \"\"\"\n",
    "    Performs consensus provenance detemrination based on a confidence treshold\n",
    "    Creates a summary statistics table\n",
    "\n",
    "    Args:\n",
    "        df: dataframe with probabilistic predictions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "     # Convert score columns to numbers\n",
    "    score_columns = ['prediction_score_CT', 'prediction_score_PCM', 'prediction_score_PDLC']\n",
    "    #for col in score_cols:\n",
    "        #df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    df['max_prob'] = df[score_columns].max(axis=1)\n",
    "    \n",
    "    results = []\n",
    "    for site in df['Site'].unique():\n",
    "        site_data = df[df['Site'] == site]\n",
    "        #n_uncertain = sum(site_data['max_prob'] < 0.70)\n",
    "        avg_uncertain = sum(site_data['max_prob'] < 0.70)/ len(site_data)*100\n",
    "        high_conf = site_data[site_data['max_prob'] > 0.70]\n",
    "        median_entropy = site_data.entropy.median()\n",
    "        \n",
    "        if len(high_conf) > 0:\n",
    "            consensus = high_conf['Uncertainty_treshold_predictions'].mode().iloc[0] # majority vote as mode of high confidence samples\n",
    "            consistency = sum(high_conf['Uncertainty_treshold_predictions'] == consensus) / len(high_conf)\n",
    "            n_consensus_pred = len(high_conf)  # Número de predicciones usadas\n",
    "        else:\n",
    "            consensus = 'No consensus'\n",
    "            consistency = 0\n",
    "            n_consensus_pred = 0\n",
    "            \n",
    "        results.append({\n",
    "            'Site': site,\n",
    "            'Samples_analyzed': len(site_data),\n",
    "            'Gavá': len(site_data[site_data['Original_predictions'] == 'CT']) ,\n",
    "            'Encinasola': len(site_data[site_data['Original_predictions'] == 'PCM']),\n",
    "            'Aliste': len(site_data[site_data['Original_predictions'] == 'PDLC']),\n",
    "            'Uncertain(%)': round(avg_uncertain),\n",
    "            'Samples_for_provenance': n_consensus_pred,\n",
    "            'Median_entropy': round(median_entropy,2),\n",
    "            'Consensus': consensus,\n",
    "            'Homogeneity': round(consistency,2)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec194946-33ee-40a8-b8a5-2e60ab6824e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Samples_analyzed</th>\n",
       "      <th>Gavá</th>\n",
       "      <th>Encinasola</th>\n",
       "      <th>Aliste</th>\n",
       "      <th>Uncertain(%)</th>\n",
       "      <th>Samples_for_provenance</th>\n",
       "      <th>Median_entropy</th>\n",
       "      <th>Consensus</th>\n",
       "      <th>Homogeneity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can Sadurni</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1.49</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roca de L'ivet</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.46</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La serreta</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>0.88</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cova Cassimanya</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.41</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Valle de las Higueras</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>241</td>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>0.88</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peñas Quiruelas</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>0.76</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Luffang</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.72</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tumulus St Michel</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Auverné</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Josseliére</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kervilor</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Plichancourt</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dolmen de Alberite</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.34</td>\n",
       "      <td>CT</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Paternanbidea</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.56</td>\n",
       "      <td>PDLC</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Can Gambús I</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>0.23</td>\n",
       "      <td>CT</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Site  Samples_analyzed  Gavá  Encinasola  Aliste  \\\n",
       "0             Can Sadurni                 8     6           0       2   \n",
       "1          Roca de L'ivet                16     1           3      12   \n",
       "2              La serreta                59    58           0       1   \n",
       "3         Cova Cassimanya                12    10           0       2   \n",
       "4   Valle de las Higueras               276    14          21     241   \n",
       "5         Peñas Quiruelas                52     0           5      47   \n",
       "6                 Luffang                 9     0           0       9   \n",
       "7       Tumulus St Michel                 3     0           0       3   \n",
       "8                 Auverné                 3     0           0       3   \n",
       "9              Josseliére                 9     0           0       9   \n",
       "10               Kervilor                35     0           0      35   \n",
       "11           Plichancourt                 2     0           0       2   \n",
       "12     Dolmen de Alberite                10     9           0       1   \n",
       "13          Paternanbidea                 4     1           0       3   \n",
       "14           Can Gambús I                78    74           1       3   \n",
       "\n",
       "    Uncertain(%)  Samples_for_provenance  Median_entropy Consensus  \\\n",
       "0             75                       2            1.49        CT   \n",
       "1             94                       1            1.46      PDLC   \n",
       "2             27                      42            0.88        CT   \n",
       "3             75                       3            1.41        CT   \n",
       "4             31                     191            0.88      PDLC   \n",
       "5             19                      42            0.76      PDLC   \n",
       "6              0                       9            0.72      PDLC   \n",
       "7              0                       3            0.71      PDLC   \n",
       "8              0                       3            0.71      PDLC   \n",
       "9              0                       9            0.71      PDLC   \n",
       "10             0                      35            0.71      PDLC   \n",
       "11             0                       2            0.74      PDLC   \n",
       "12            10                       9            0.34        CT   \n",
       "13            25                       3            0.56      PDLC   \n",
       "14             5                      74            0.23        CT   \n",
       "\n",
       "    Homogeneity  \n",
       "0          1.00  \n",
       "1          1.00  \n",
       "2          1.00  \n",
       "3          1.00  \n",
       "4          0.97  \n",
       "5          0.98  \n",
       "6          1.00  \n",
       "7          1.00  \n",
       "8          1.00  \n",
       "9          1.00  \n",
       "10         1.00  \n",
       "11         1.00  \n",
       "12         1.00  \n",
       "13         1.00  \n",
       "14         0.99  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = provenance_determination(results)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f76c2-f826-4fdf-8f33-0df876314563",
   "metadata": {},
   "source": [
    "def plot_function:\n",
    "- Create uncertain plot\n",
    "- Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457b1de-0434-4eee-bb69-65c9b9aaaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_site_entropy_distribution_median(df, output_file='site_entropy_distribution_median.png'):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates an entropy and probility distribution plot\n",
    "\n",
    "    Args:\n",
    "        df: dataframe with probabilistic predictions\n",
    "        output_file: file with pre-defined format\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Preparing data\n",
    "    score_cols = ['prediction_score_CT', 'prediction_score_PCM', 'prediction_score_PDLC']\n",
    "    for col in score_cols:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    # Calculate entropy per sample\n",
    "    df['entropy'] = df[score_cols].apply(lambda x: entropy(x, base=2), axis=1)\n",
    "    \n",
    "    # Calcular  ENTROPIA mediana por sitio\n",
    "    site_medians = df.groupby('Site')[score_cols + ['entropy']].median()\n",
    "    \n",
    "    # Configure the chart style\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    bottom = np.zeros(len(site_medians))\n",
    "    colors = ['#4B0082', '#228B22', '#B8860B']  # Colores para CT, PCM, PDLC\n",
    "    \n",
    "    # Direct use of site names as x-positions\n",
    "    x = np.arange(len(site_medians.index))\n",
    "    \n",
    "    for i, col in enumerate(score_cols):\n",
    "        ax.bar(x, site_medians[col], bottom=bottom, \n",
    "               label=col.replace('prediction_score_', ''),\n",
    "               color=colors[i], alpha=0.7)\n",
    "        bottom += site_medians[col]\n",
    "    \n",
    "    # Add entropy line\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(x, site_medians['entropy'], \n",
    "             color='red', linewidth=2, label='Entropy', \n",
    "             marker='o')\n",
    "    \n",
    "    # Configure axes and labels\n",
    "    ax.set_xlabel('Sites', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Probability Distribution (Median)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Entropy (bits)', fontsize=12, fontweight='bold', color='red')\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(site_medians.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Adjust captions\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, \n",
    "             loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    \n",
    "    # Adjust layout to prevent labels from being cut off\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(output_file, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Imprimir estadísticas completas por sitio\n",
    "    print(\"\\nEstadísticas por sitio:\")\n",
    "    stats = pd.DataFrame({\n",
    "        'median_CT': site_medians['prediction_score_CT'],\n",
    "        'median_PCM': site_medians['prediction_score_PCM'],\n",
    "        'median_PDLC': site_medians['prediction_score_PDLC'],\n",
    "        'median_entropy': site_medians['entropy'],\n",
    "        'n_samples': df.groupby('Site').size(),\n",
    "        'mean_entropy': df.groupby('Site')['entropy'].mean(),\n",
    "        'std_entropy': df.groupby('Site')['entropy'].std()\n",
    "    }).round(3)\n",
    "    \n",
    "    print(stats)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56326fc-29c8-4eab-872a-9a8043a5356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos y crear gráfico\n",
    "df = pd.read_csv('/home/dsg/VORTEX_FINAL/PRODUCTION/DATA/20241118_PrediccionesVortexTodas.csv',encoding='latin-1')\n",
    "stats = plot_site_entropy_distribution_median(df).astype(float)\n",
    "stats.to_csv('20250123_median_probabilities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb5cff-8dc2-43c4-b883-b95bbfae4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_site_entropy_distribution_median(df, output_file='site_entropy_distribution_median.png'):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates an entropy and probility distribution plot\n",
    "\n",
    "    Args:\n",
    "        df: dataframe with probabilistic predictions\n",
    "        output_file: file with pre-defined format\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Preparing data\n",
    "    score_cols = ['prediction_score_CT', 'prediction_score_PCM', 'prediction_score_PDLC']\n",
    "    for col in score_cols:\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    # Calculate entropy per sample\n",
    "    df['entropy'] = df[score_cols].apply(lambda x: entropy(x, base=2), axis=1)\n",
    "    \n",
    "    # Calcular  ENTROPIA mediana por sitio\n",
    "    site_medians = df.groupby('Site')[score_cols + ['entropy']].median()\n",
    "    \n",
    "    # Configure the chart style\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    bottom = np.zeros(len(site_medians))\n",
    "    colors = ['#4B0082', '#228B22', '#B8860B']  # Colores para CT, PCM, PDLC\n",
    "    \n",
    "    # Direct use of site names as x-positions\n",
    "    x = np.arange(len(site_medians.index))\n",
    "    \n",
    "    for i, col in enumerate(score_cols):\n",
    "        ax.bar(x, site_medians[col], bottom=bottom, \n",
    "               label=col.replace('prediction_score_', ''),\n",
    "               color=colors[i], alpha=0.7)\n",
    "        bottom += site_medians[col]\n",
    "    \n",
    "    # Add entropy line\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(x, site_medians['entropy'], \n",
    "             color='red', linewidth=2, label='Entropy', \n",
    "             marker='o')\n",
    "    \n",
    "    # Configure axes and labels\n",
    "    ax.set_xlabel('Sites', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Probability Distribution (Median)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Entropy (bits)', fontsize=12, fontweight='bold', color='red')\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(site_medians.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Adjust captions\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, \n",
    "             loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    \n",
    "    # Adjust layout to prevent labels from being cut off\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(output_file, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Imprimir estadísticas completas por sitio\n",
    "    print(\"\\nEstadísticas por sitio:\")\n",
    "    stats = pd.DataFrame({\n",
    "        'median_CT': site_medians['prediction_score_CT'],\n",
    "        'median_PCM': site_medians['prediction_score_PCM'],\n",
    "        'median_PDLC': site_medians['prediction_score_PDLC'],\n",
    "        'median_entropy': site_medians['entropy'],\n",
    "        'n_samples': df.groupby('Site').size(),\n",
    "        'mean_entropy': df.groupby('Site')['entropy'].mean(),\n",
    "        'std_entropy': df.groupby('Site')['entropy'].std()\n",
    "    }).round(3)\n",
    "    \n",
    "    print(stats)\n",
    "    \n",
    "    return stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
